{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced 3D Reconstruction Visualization for Interior Reimaginer\n",
    "\n",
    "This notebook demonstrates advanced 3D visualization techniques for the Interior Reimaginer project, highlighting superior alternatives to standard Plotly visualizations. We'll showcase GAN and diffusion-based depth enhancement methods for improved 3D reconstruction quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's clone the repository and install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/your-username/CV_Project.git\n",
    "\n",
    "%cd CV_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r interior_reimaginer/requirements.txt\n",
    "\n",
    "# Additional packages for advanced visualization\n",
    "!pip install open3d matplotlib plotly pyrender trimesh pyglet==1.5.27 PyOpenGL PyOpenGL-accelerate ipywidgets ipyvolume k3d pythreejs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Import Issues\n",
    "\n",
    "Let's modify the `__init__.py` files to avoid import errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary fix for the models/__init__.py file to avoid UI import\n",
    "%%writefile interior_reimaginer/models/__init__.py\n",
    "# models/__init__.py\n",
    "from .image_processor import ImageProcessor, ProcessedImage, RoomSegmentClass\n",
    "from .interior_reimaginer import InteriorReimaginer\n",
    "from .design_styles import DesignStyle, load_design_styles\n",
    "\n",
    "__all__ = [\n",
    "    'ImageProcessor', \n",
    "    'ProcessedImage', \n",
    "    'RoomSegmentClass', \n",
    "    'InteriorReimaginer', \n",
    "    'DesignStyle', \n",
    "    'load_design_styles'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML, display\n",
    "import ipyvolume as ipv\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import IFrame\n",
    "\n",
    "# Make sure Python can find our modules\n",
    "sys.path.append('/content/CV_Project')\n",
    "\n",
    "# Import our project modules directly to avoid potential issues\n",
    "try:\n",
    "    from interior_reimaginer.models.interior_reimaginer import InteriorReimaginer\n",
    "    from interior_reimaginer.models.reconstruction_3d import DepthReconstructor\n",
    "    print(\"Successfully imported project modules\")\n",
    "except Exception as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Attempting alternative imports...\")\n",
    "    # Try direct imports as a fallback\n",
    "    sys.path.insert(0, '/content/CV_Project/interior_reimaginer')\n",
    "    from models.reconstruction_3d import DepthReconstructor\n",
    "    from models.interior_reimaginer import InteriorReimaginer\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "try:\n",
    "    reimaginer = InteriorReimaginer(device=device)\n",
    "    depth_reconstructor = DepthReconstructor()\n",
    "    print(\"Models initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing models: {e}\")\n",
    "    print(\"Initializing only DepthReconstructor as fallback...\")\n",
    "    depth_reconstructor = DepthReconstructor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload or Create Test Image\n",
    "\n",
    "You can either upload your own interior image or use a test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Upload an image\n",
    "try:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()  # This will prompt you to upload an image\n",
    "    \n",
    "    if uploaded:\n",
    "        image_name = list(uploaded.keys())[0]\n",
    "        image = Image.open(io.BytesIO(uploaded[image_name]))\n",
    "    else:  # If no upload, create a simple test image\n",
    "        raise ValueError(\"No image uploaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with image upload: {e}\")\n",
    "    print(\"Creating a test image...\")\n",
    "    # Create a simple test image with a gradient\n",
    "    width, height = 800, 600\n",
    "    img_array = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            img_array[i, j] = [int(255*i/height), int(255*j/width), 100]\n",
    "    image = Image.fromarray(img_array)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(image)\n",
    "plt.title(\"Image for Processing\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Image\n",
    "\n",
    "We'll process the image to extract depth information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing the image...\")\n",
    "depth_map = None\n",
    "processed = None\n",
    "\n",
    "try:\n",
    "    # Try to use the reimaginer's image_processor if available\n",
    "    processed = reimaginer.image_processor.process_image(image)\n",
    "    if processed and processed.depth_map is not None:\n",
    "        depth_map = processed.depth_map\n",
    "        print(\"Image processing complete with reimaginer!\")\n",
    "    else:\n",
    "        raise ValueError(\"No depth map generated by reimaginer\")\n",
    "except Exception as e:\n",
    "    print(f\"Error processing with reimaginer: {e}\")\n",
    "    print(\"Creating a synthetic depth map for visualization...\")\n",
    "    \n",
    "    # Create a simple synthetic depth map if processing fails\n",
    "    img_array = np.array(image)\n",
    "    height, width = img_array.shape[:2]\n",
    "    \n",
    "    # Create a gradient depth map\n",
    "    x = np.linspace(0, 1, width)\n",
    "    y = np.linspace(0, 1, height)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    # Make depth a function of distance from center\n",
    "    center_x, center_y = width / 2, height / 2\n",
    "    xx_centered = xx * width - center_x\n",
    "    yy_centered = yy * height - center_y\n",
    "    depth_map = np.sqrt(xx_centered**2 + yy_centered**2)\n",
    "    \n",
    "    # Normalize to 0-255 range\n",
    "    depth_map = 255 * (1 - depth_map / depth_map.max())\n",
    "    depth_map = depth_map.astype(np.uint8)\n",
    "\n",
    "# Display the depth map\n",
    "if depth_map is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(depth_map, cmap='inferno')\n",
    "    plt.title(\"Depth Map\")\n",
    "    plt.colorbar(label=\"Depth\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Depth map generation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced 3D Visualization Methods\n",
    "\n",
    "Let's explore different advanced visualization techniques beyond standard Plotly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Enhanced Depth Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply high-quality render with improved colormaps\n",
    "try:\n",
    "    enhanced_depth_viz = depth_reconstructor.render_depth_map(\n",
    "        depth_map, \n",
    "        colormap=cv2.COLORMAP_TURBO,  # Try different colormaps: COLORMAP_TURBO, COLORMAP_JET, COLORMAP_VIRIDIS\n",
    "        width=1000, \n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(enhanced_depth_viz)\n",
    "    plt.title(\"Enhanced Depth Map Visualization\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error rendering enhanced depth map: {e}\")\n",
    "    # Fallback to basic visualization\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(depth_map, cmap='turbo')\n",
    "    plt.title(\"Basic Depth Map Visualization\")\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(label=\"Depth\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GAN-Based Enhanced 3D Reconstruction\n",
    "\n",
    "Use GAN-based depth enhancement to improve the quality of the 3D reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating GAN-enhanced 3D reconstruction...\")\n",
    "try:\n",
    "    gan_render_img, gan_pcd = depth_reconstructor.enhanced_reconstruction(\n",
    "        depth_map=depth_map,\n",
    "        image=image,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        use_gan=True,  # Enable GAN enhancement\n",
    "        solid_rendering=True  # Use solid rendering for more realistic visualization\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(gan_render_img)\n",
    "    plt.title(\"GAN-Enhanced 3D Reconstruction\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error with GAN-enhanced reconstruction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Diffusion-Based Enhanced 3D Reconstruction\n",
    "\n",
    "Use diffusion-based depth enhancement for a different approach to improving 3D reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating diffusion-enhanced 3D reconstruction...\")\n",
    "try:\n",
    "    diffusion_render_img, diffusion_pcd = depth_reconstructor.diffusion_reconstruction(\n",
    "        depth_map=depth_map,\n",
    "        image=image,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        solid_rendering=True  # Use solid rendering for more realistic visualization\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(diffusion_render_img)\n",
    "    plt.title(\"Diffusion-Enhanced 3D Reconstruction\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error with diffusion-enhanced reconstruction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Local Region Models (LRM) Reconstruction\n",
    "\n",
    "Use LRM for more detailed local geometry processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating LRM 3D reconstruction...\")\n",
    "try:\n",
    "    lrm_render_img, lrm_pcd = depth_reconstructor.lrm_reconstruction(\n",
    "        depth_map=depth_map,\n",
    "        image=image,\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        downsample_factor=2,\n",
    "        patch_size=32,\n",
    "        overlap=8,\n",
    "        solid_rendering=True\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.imshow(lrm_render_img)\n",
    "    plt.title(\"LRM-Enhanced 3D Reconstruction\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error with LRM reconstruction: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive 3D Visualization with HTML Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_pointcloud_visualization(pcd, width=900, height=600):\n",
    "    \"\"\"Create an interactive 3D visualization using Plotly\"\"\"\n",
    "    # Convert Open3D point cloud to numpy arrays\n",
    "    points = np.asarray(pcd.points)\n",
    "    colors = np.asarray(pcd.colors)\n",
    "    \n",
    "    # Convert RGB to hex for Plotly\n",
    "    hex_colors = [f'rgb({int(r*255)},{int(g*255)},{int(b*255)})' for r, g, b in colors]\n",
    "    \n",
    "    # Create a 3D scatter plot\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=points[:, 0],\n",
    "        y=points[:, 2],  # Use z as y for better orientation\n",
    "        z=-points[:, 1],  # Negative y for correct orientation\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=hex_colors,\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Set up the layout\n",
    "    fig.update_layout(\n",
    "        width=width,\n",
    "        height=height,\n",
    "        scene=dict(aspectmode='data'),\n",
    "        margin=dict(l=0, r=0, b=0, t=30),\n",
    "        title=\"Interactive 3D Reconstruction\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Initialize default point cloud if needed\n",
    "if 'gan_pcd' not in locals() and 'diffusion_pcd' not in locals() and 'lrm_pcd' not in locals():\n",
    "    print(\"Creating a simple point cloud for visualization...\")\n",
    "    # Create a simple point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    points = []\n",
    "    colors = []\n",
    "    for i in range(1000):\n",
    "        points.append([(np.random.rand()-0.5)*2, (np.random.rand()-0.5)*2, (np.random.rand()-0.5)*2])\n",
    "        colors.append([np.random.rand(), np.random.rand(), np.random.rand()])\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    best_pcd = pcd\n",
    "else:\n",
    "    # Use the best available point cloud based on point count\n",
    "    if 'lrm_pcd' in locals() and len(lrm_pcd.points) > 0:\n",
    "        best_pcd = lrm_pcd\n",
    "    elif 'diffusion_pcd' in locals() and len(diffusion_pcd.points) > 0:\n",
    "        best_pcd = diffusion_pcd\n",
    "    elif 'gan_pcd' in locals() and len(gan_pcd.points) > 0:\n",
    "        best_pcd = gan_pcd\n",
    "    else:\n",
    "        # Create a simple point cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        points = []\n",
    "        colors = []\n",
    "        for i in range(1000):\n",
    "            points.append([(np.random.rand()-0.5)*2, (np.random.rand()-0.5)*2, (np.random.rand()-0.5)*2])\n",
    "            colors.append([np.random.rand(), np.random.rand(), np.random.rand()])\n",
    "        pcd.points = o3d.utility.Vector3dVector(points)\n",
    "        pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "        best_pcd = pcd\n",
    "\n",
    "# Create and display interactive visualization\n",
    "try:\n",
    "    interactive_fig = create_interactive_pointcloud_visualization(best_pcd)\n",
    "    interactive_fig.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating interactive visualization: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh Visualization\n",
    "\n",
    "Create and visualize a 3D mesh from the point cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating mesh from point cloud...\")\n",
    "try:\n",
    "    if len(best_pcd.points) > 100:\n",
    "        # Smooth the point cloud for better mesh generation\n",
    "        best_pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "        best_pcd.orient_normals_towards_camera_location()\n",
    "        \n",
    "        # Create mesh\n",
    "        mesh = depth_reconstructor.pointcloud_to_mesh(best_pcd)\n",
    "        print(f\"Mesh created with {len(mesh.triangles)} triangles\")\n",
    "        \n",
    "        # Render mesh\n",
    "        mesh_image = depth_reconstructor.render_mesh_image(mesh, width=1000, height=800)\n",
    "        \n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.imshow(mesh_image)\n",
    "        plt.title(\"3D Mesh Reconstruction\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save mesh to OBJ file\n",
    "        timestamp = int(time.time())\n",
    "        mesh_path = depth_reconstructor.save_mesh(mesh, f\"interior_mesh_{timestamp}\")\n",
    "        print(f\"Mesh saved to: {mesh_path}\")\n",
    "        \n",
    "        # Download the mesh file\n",
    "        from google.colab import files\n",
    "        files.download(mesh_path)\n",
    "    else:\n",
    "        print(\"Not enough points in point cloud for mesh generation\")\n",
    "except Exception as e:\n",
    "    print(f\"Mesh creation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated several advanced 3D visualization techniques for interior reconstruction:\n",
    "\n",
    "1. Enhanced depth map rendering with improved colormaps\n",
    "2. GAN-based depth enhancement for better 3D reconstruction\n",
    "3. Diffusion-based methods for filling in missing depth information\n",
    "4. Local Region Models (LRM) for detailed geometry processing\n",
    "5. Interactive 3D visualizations and mesh creation\n",
    "\n",
    "These techniques provide significant improvements over standard Plotly visualizations, offering better detail, more realistic rendering, and enhanced interactivity for exploring 3D reconstructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

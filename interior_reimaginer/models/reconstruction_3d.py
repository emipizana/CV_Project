import os
import numpy as np
import open3d as o3d
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
from PIL import Image
import cv2
import logging
import io
import base64
from typing import List, Dict, Tuple, Optional, Union, Any, Literal

logger = logging.getLogger(__name__)

class DepthReconstructor:
    """
    Class for 3D reconstruction and visualization from depth maps generated by the ImageProcessor
    """
    
    def __init__(self):
        """Initialize the 3D reconstruction module"""
        logger.info("Initializing 3D Reconstructor")
        
        # Define all available visualization methods
        self.visualization_methods = {
            "depth_map": "Colored Depth Map (2D)",
            "pointcloud_mpl": "Matplotlib Point Cloud (3D)",
            "enhanced_3d": "Enhanced 3D Reconstruction"
        }
    
    def render_depth_map(self, depth_map: np.ndarray, colormap: int = cv2.COLORMAP_INFERNO,
                         width: int = 800, height: int = 600) -> np.ndarray:
        """
        Render a depth map using OpenCV's colormaps for direct visualization.
        This is the most reliable visualization method and serves as a fallback.
        
        Args:
            depth_map: Depth map as numpy array
            colormap: OpenCV colormap to use
            width: Desired output width
            height: Desired output height
            
        Returns:
            Rendered colorized depth map as numpy array
        """
        logger.info(f"Rendering depth map with colormap {colormap}")
        
        # Ensure depth map is valid
        if depth_map is None or depth_map.size == 0:
            logger.warning("Invalid depth map provided")
            return np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            
        # Normalize depth map to 0-255 range
        if depth_map.max() > 0:
            normalized = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
        else:
            logger.warning("Depth map has no valid depth values")
            return np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
        
        # Apply colormap
        colored = cv2.applyColorMap(normalized, colormap)
        
        # Resize to desired dimensions
        if colored.shape[0] != height or colored.shape[1] != width:
            colored = cv2.resize(colored, (width, height))
        
        # Convert to RGB (from BGR)
        colored_rgb = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)
        
        # Normalize to 0-1 for consistent output format
        return colored_rgb.astype(np.float32) / 255.0
        
    def render_pointcloud_matplotlib(self, depth_map: np.ndarray, image: Image.Image,
                                   width: int = 800, height: int = 600,
                                   downsample_factor: int = 4) -> np.ndarray:
        """
        Render a 3D point cloud using Matplotlib instead of Open3D.
        This can serve as a fallback when Open3D visualization fails.
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud for rendering
            
        Returns:
            Rendered point cloud as numpy array
        """
        logger.info(f"Rendering point cloud with Matplotlib (downsample={downsample_factor})")
        
        try:
            # Create a figure with the right dimensions
            dpi = 100
            fig = plt.figure(figsize=(width/dpi, height/dpi), dpi=dpi)
            ax = fig.add_subplot(111, projection='3d')
            
            # Normalize depth map
            if depth_map.max() <= 255:
                depth_norm = depth_map.astype(np.float32) / 255.0
            else:
                depth_norm = depth_map.astype(np.float32) / 1000.0

            # Get color image as RGB numpy array
            color_img = np.array(image.convert('RGB'))
            
            # Ensure dimensions match
            if color_img.shape[:2] != depth_map.shape[:2]:
                color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
            
            # Downsample for better performance
            h, w = depth_norm.shape
            y_indices, x_indices = np.mgrid[0:h:downsample_factor, 0:w:downsample_factor]
            
            # Get 3D coordinates
            z = depth_norm[y_indices, x_indices]
            x = x_indices
            y = y_indices
            colors = color_img[y_indices, x_indices] / 255.0
            
            # Flatten arrays for scatter plot
            x = x.flatten()
            y = y.flatten()
            z = z.flatten()
            colors = colors.reshape(-1, 3)
            
            # Filter out invalid points
            valid = (z > 0)
            x = x[valid]
            y = y[valid]
            z = z[valid]
            colors = colors[valid]
            
            # Normalize spatial coordinates
            x = (x - w/2) / w
            y = (y - h/2) / h
            
            # Create scatter plot with colors
            ax.scatter(x, z, y, c=colors, s=2, alpha=0.8)  # Note: y and z are swapped for better visualization
            
            # Set equal aspect ratio and labels
            ax.set_box_aspect([1, 1, 1])
            ax.set_xlabel('X')
            ax.set_ylabel('Z (Depth)')
            ax.set_zlabel('Y')
            ax.set_title('3D Point Cloud (Matplotlib)')
            
            # Use light gray background for better visibility
            ax.set_facecolor([0.8, 0.8, 0.8])
            fig.patch.set_facecolor([0.8, 0.8, 0.8])
            
            # Set a good viewpoint
            ax.view_init(elev=30, azim=-60)
            
            # Capture the plot as an image
            fig.tight_layout(pad=0)
            with io.BytesIO() as buf:
                fig.savefig(buf, format='png', bbox_inches='tight', facecolor=fig.get_facecolor())
                buf.seek(0)
                img = np.array(Image.open(buf))
            
            # Close the figure to free memory
            plt.close(fig)
            
            # Convert to float32 and normalize
            return img.astype(np.float32) / 255.0
            
        except Exception as e:
            logger.warning(f"Error rendering with Matplotlib: {str(e)}")
            # Fall back to a simple depth map visualization
            return self.render_depth_map(depth_map, width=width, height=height)
    
    def depth_to_pointcloud(self, 
                           depth_map: np.ndarray, 
                           image: Image.Image,
                           focal_length: float = 525.0, 
                           scale_factor: float = 1000.0,
                           downsample_factor: int = 2) -> o3d.geometry.PointCloud:
        """
        Convert a depth map to a 3D point cloud
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image corresponding to the depth map
            focal_length: Camera focal length (approximation)
            scale_factor: Depth scale factor
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Open3D PointCloud object
        """
        logger.info(f"Converting depth map to point cloud (downsample={downsample_factor})")
        
        # Ensure depth_map is properly scaled from 0-255 to actual depth values
        if depth_map.max() <= 255:
            depth_norm = depth_map.astype(np.float32) / 255.0
        else:
            depth_norm = depth_map.astype(np.float32) / scale_factor
            
        # Get color image as RGB numpy array
        color_img = np.array(image.convert('RGB'))
        
        # Ensure dimensions match
        if color_img.shape[:2] != depth_map.shape[:2]:
            color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
        
        # Downsample for better performance
        if downsample_factor > 1:
            depth_norm = depth_norm[::downsample_factor, ::downsample_factor]
            color_img = color_img[::downsample_factor, ::downsample_factor]
            
        # Get image dimensions
        height, width = depth_norm.shape
        
        # Create meshgrid of coordinates
        y, x = np.mgrid[0:height, 0:width]
        
        # Compute 3D coordinates
        # Center the coordinate system at the image center
        cx, cy = width / 2, height / 2
        x = (x - cx) * depth_norm / focal_length
        y = (y - cy) * depth_norm / focal_length
        z = depth_norm
        
        # Flatten and combine into points
        points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)
        colors = color_img.reshape(-1, 3) / 255.0
        
        # Remove invalid points (zero depth)
        valid_indices = z.flatten() > 0
        points = points[valid_indices]
        colors = colors[valid_indices]
        
        # Create Open3D point cloud
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # Optionally filter noise and outliers
        pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
        
        return pcd
    
    def pointcloud_to_mesh(self, pcd: o3d.geometry.PointCloud, depth_threshold: float = 0.05) -> o3d.geometry.TriangleMesh:
        """
        Convert point cloud to mesh
        
        Args:
            pcd: Open3D PointCloud
            depth_threshold: Threshold for depth difference between connected points
            
        Returns:
            Open3D TriangleMesh
        """
        logger.info("Converting point cloud to mesh")
        
        # Estimate normals if they don't exist
        if not pcd.has_normals():
            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
            pcd.orient_normals_towards_camera_location()
        
        # Create mesh using Poisson surface reconstruction
        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)
        
        # Remove low density vertices
        vertices_to_remove = densities < np.quantile(densities, 0.1)
        mesh.remove_vertices_by_mask(vertices_to_remove)
        
        return mesh
    
    def save_pointcloud(self, pcd: o3d.geometry.PointCloud, filename: str) -> str:
        """
        Save point cloud to file
        
        Args:
            pcd: Open3D PointCloud
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as PLY
        output_path = f"{filename}.ply"
        o3d.io.write_point_cloud(output_path, pcd)
        logger.info(f"Point cloud saved to {output_path}")
        return output_path
    
    def save_mesh(self, mesh: o3d.geometry.TriangleMesh, filename: str) -> str:
        """
        Save mesh to file
        
        Args:
            mesh: Open3D TriangleMesh
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as OBJ
        output_path = f"{filename}.obj"
        o3d.io.write_triangle_mesh(output_path, mesh)
        logger.info(f"Mesh saved to {output_path}")
        return output_path
    
    def visualize_pointcloud(self, pcd: o3d.geometry.PointCloud) -> None:
        """
        Visualize point cloud using Open3D visualizer
        
        Args:
            pcd: Open3D PointCloud
        """
        o3d.visualization.draw_geometries([pcd])
    
    def visualize_mesh(self, mesh: o3d.geometry.TriangleMesh) -> None:
        """
        Visualize mesh using Open3D visualizer
        
        Args:
            mesh: Open3D TriangleMesh
        """
        o3d.visualization.draw_geometries([mesh])
    
    def render_pointcloud_image(self, pcd: o3d.geometry.PointCloud, 
                               width: int = 800, height: int = 600,
                               zoom: float = 0.8) -> np.ndarray:
        """
        Render point cloud to image without opening a window
        
        Args:
            pcd: Open3D PointCloud
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering point cloud with {len(pcd.points)} points")
        
        # Check if point cloud has points
        if len(pcd.points) == 0:
            logger.warning("Point cloud is empty, creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(pcd)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire point cloud
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the point cloud
                bbox = pcd.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().point_size = 3.0  # Larger points
            
            # Debugging camera info
            logger.info(f"Camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered image appears to be all black, creating a fallback")
                # Create a fallback with a message
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering point cloud: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
    
    def render_mesh_image(self, mesh: o3d.geometry.TriangleMesh, 
                         width: int = 800, height: int = 600,
                         zoom: float = 0.8) -> np.ndarray:
        """
        Render mesh to image without opening a window
        
        Args:
            mesh: Open3D TriangleMesh
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering mesh with {len(mesh.triangles)} triangles")
        
        # Check if mesh is valid
        if len(mesh.triangles) == 0:
            logger.warning("Mesh is empty (no triangles), creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(mesh)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire mesh
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the mesh
                bbox = mesh.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().mesh_show_back_face = True
            vis.get_render_option().light_on = True
            
            # Debugging camera info
            logger.info(f"Mesh camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered mesh image appears to be all black, creating a fallback")
                
                # Add a white grid pattern to gray background to show something
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                
                # Create mesh texture visualization
                for i in range(0, height, 20):
                    for j in range(0, width, 20):
                        # Create a grid pattern
                        if (i + j) % 40 == 0:
                            fallback_img[i:i+10, j:j+10] = [0.9, 0.9, 0.9]  # Make squares lighter
                
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering mesh: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img

    def enhanced_reconstruction(self, depth_map: np.ndarray, image: Image.Image,
                              width: int = 800, height: int = 600,
                              downsample_factor: int = 2) -> Tuple[np.ndarray, o3d.geometry.PointCloud]:
        """
        Create an enhanced 3D reconstruction using depth gradient analysis and confidence-based filtering
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Tuple of (rendered image, point cloud)
        """
        logger.info("Creating enhanced 3D reconstruction...")
        
        try:
            # Calculate depth confidence using gradient analysis
            # Areas with high gradient (edges) are less reliable
            depth_gradx = cv2.Sobel(depth_map, cv2.CV_32F, 1, 0, ksize=3)
            depth_grady = cv2.Sobel(depth_map, cv2.CV_32F, 0, 1, ksize=3)
            depth_grad_mag = np.sqrt(depth_gradx**2 + depth_grady**2)
            
            # Normalize gradient magnitude
            if depth_grad_mag.max() > 0:
                confidence = 1.0 - (depth_grad_mag / depth_grad_mag.max())
            else:
                confidence = np.ones_like(depth_map)
            
            # Apply confidence threshold
            confidence_mask = confidence > 0.7  # Only keep points with high confidence
            
            # Apply confidence mask to depth map
            filtered_depth = depth_map.copy()
            filtered_depth[~confidence_mask] = 0
            
            # Create a higher quality point cloud with confidence filtering
            pcd = self.depth_to_pointcloud(
                depth_map=filtered_depth,
                image=image,
                downsample_factor=downsample_factor
            )
            
            # Render the enhanced point cloud using Open3D
            try:
                # Try Open3D rendering first
                render_img = self.render_pointcloud_image(pcd, width=width, height=height, zoom=0.7)
                
                # Check if valid (not too dark)
                if render_img.mean() < 0.1:
                    raise Exception("Open3D rendering too dark")
                    
            except Exception as e:
                logger.warning(f"Enhanced 3D Open3D visualization failed: {str(e)}")
                
                # Fall back to Matplotlib rendering
                render_img = self.render_pointcloud_matplotlib(
                    depth_map=filtered_depth, 
                    image=image,
                    width=width,
                    height=height,
                    downsample_factor=max(1, downsample_factor)
                )
                
            return render_img, pcd
            
        except Exception as e:
            logger.error(f"Enhanced reconstruction failed: {str(e)}")
            # Return default depth map and empty point cloud as fallback
            render_img = self.render_depth_map(depth_map, width=width, height=height)
            pcd = o3d.geometry.PointCloud()  # Empty point cloud
            return render_img, pcd
            
    def visualize_3d(self, depth_map: np.ndarray, image: Image.Image, 
                    method: str = "depth_map", width: int = 800, height: int = 600) -> np.ndarray:
        """
        Unified method to visualize depth data using various methods with automatic fallbacks
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            method: Visualization method to use (from self.visualization_methods)
            width: Desired output width
            height: Desired output height
            
        Returns:
            Visualization as numpy array (RGB float image)
        """
        logger.info(f"Visualizing 3D with method: {method}")
        
        # First check if the method is valid
        if method not in self.visualization_methods:
            logger.warning(f"Invalid visualization method: {method}, falling back to depth_map")
            method = "depth_map"
            
        # Check if inputs are valid
        if depth_map is None or depth_map.size == 0:
            logger.warning("Invalid depth map provided")
            error_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            # Add a message about the error
            return error_img
        
        # Process based on method with fallbacks
        try:
            if method == "depth_map":
                # Direct depth map visualization (most reliable)
                return self.render_depth_map(depth_map, width=width, height=height)
                
            elif method == "pointcloud_mpl":
                # Matplotlib point cloud visualization (good fallback)
                return self.render_pointcloud_matplotlib(depth_map, image, 
                                                      width=width, height=height)
                
            elif method == "enhanced_3d":
                # Use the enhanced 3D reconstruction
                render_img, _ = self.enhanced_reconstruction(
                    depth_map=depth_map,
                    image=image,
                    width=width,
                    height=height
                )
                return render_img
                
            else:
                # Unknown method, fall back to depth map
                logger.warning(f"Unknown visualization method: {method}, falling back to depth_map")
                return self.render_depth_map(depth_map, width=width, height=height)
                
        except Exception as e:
            # If all else fails, fall back to direct depth map visualization
            logger.warning(f"3D visualization failed with error: {str(e)}, falling back to depth map")
            return self.render_depth_map(depth_map, width=width, height=height)

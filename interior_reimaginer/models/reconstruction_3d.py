import os
import numpy as np
import open3d as o3d
import matplotlib.pyplot as plt
from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
import pyvista as pv
from PIL import Image
import cv2
import logging
import io
import base64
from typing import List, Dict, Tuple, Optional, Union, Any, Literal, Callable

logger = logging.getLogger(__name__)

class DepthReconstructor:
    """
    Class for 3D reconstruction and visualization from depth maps generated by the ImageProcessor
    """
    
    def __init__(self):
        """Initialize the 3D reconstruction module"""
        logger.info("Initializing 3D Reconstructor")
        
        # Define all available visualization methods
        self.visualization_methods = {
            "depth_map": "Colored Depth Map (2D)",
            "pointcloud_mpl": "Matplotlib Point Cloud (3D)",
            "enhanced_3d": "Enhanced 3D Reconstruction"
        }
    
    def render_depth_map(self, depth_map: np.ndarray, colormap: int = cv2.COLORMAP_INFERNO,
                         width: int = 800, height: int = 600) -> np.ndarray:
        """
        Render a depth map using OpenCV's colormaps for direct visualization.
        This is the most reliable visualization method and serves as a fallback.
        
        Args:
            depth_map: Depth map as numpy array
            colormap: OpenCV colormap to use
            width: Desired output width
            height: Desired output height
            
        Returns:
            Rendered colorized depth map as numpy array
        """
        logger.info(f"Rendering depth map with colormap {colormap}")
        
        # Ensure depth map is valid
        if depth_map is None or depth_map.size == 0:
            logger.warning("Invalid depth map provided")
            return np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            
        # Normalize depth map to 0-255 range
        if depth_map.max() > 0:
            normalized = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
        else:
            logger.warning("Depth map has no valid depth values")
            return np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
        
        # Apply colormap
        colored = cv2.applyColorMap(normalized, colormap)
        
        # Resize to desired dimensions
        if colored.shape[0] != height or colored.shape[1] != width:
            colored = cv2.resize(colored, (width, height))
        
        # Convert to RGB (from BGR)
        colored_rgb = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)
        
        # Normalize to 0-1 for consistent output format
        return colored_rgb.astype(np.float32) / 255.0
        
    def render_pointcloud_matplotlib(self, depth_map: np.ndarray, image: Image.Image,
                                   width: int = 800, height: int = 600,
                                   downsample_factor: int = 4) -> np.ndarray:
        """
        Render a 3D point cloud using Matplotlib with corrected orientation.
        This can serve as a fallback when more advanced visualization fails.
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud for rendering
            
        Returns:
            Rendered point cloud as numpy array
        """
        logger.info(f"Rendering point cloud with Matplotlib (downsample={downsample_factor})")
        
        try:
            # Create a figure with the right dimensions
            dpi = 100
            fig = plt.figure(figsize=(width/dpi, height/dpi), dpi=dpi)
            ax = fig.add_subplot(111, projection='3d')
            
            # Normalize depth map
            if depth_map.max() <= 255:
                depth_norm = depth_map.astype(np.float32) / 255.0
            else:
                depth_norm = depth_map.astype(np.float32) / 1000.0

            # Get color image as RGB numpy array
            color_img = np.array(image.convert('RGB'))
            
            # Ensure dimensions match
            if color_img.shape[:2] != depth_map.shape[:2]:
                color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
            
            # Downsample for better performance
            h, w = depth_norm.shape
            y_indices, x_indices = np.mgrid[0:h:downsample_factor, 0:w:downsample_factor]
            
            # Get 3D coordinates
            z = depth_norm[y_indices, x_indices]
            x = x_indices
            y = y_indices  # Will be inverted to correct orientation
            colors = color_img[y_indices, x_indices] / 255.0
            
            # Flatten arrays for scatter plot
            x = x.flatten()
            y = y.flatten()
            z = z.flatten()
            colors = colors.reshape(-1, 3)
            
            # Filter out invalid points
            valid = (z > 0)
            x = x[valid]
            y = y[valid]
            z = z[valid]
            colors = colors[valid]
            
            # Normalize spatial coordinates
            x = (x - w/2) / w
            y = -(y - h/2) / h  # Invert Y axis for correct orientation
            
            # Create scatter plot with colors
            # Use x, z, -y for correct orientation (negative y makes the model upright)
            ax.scatter(x, z, -y, c=colors, s=3, alpha=0.8)
            
            # Set equal aspect ratio and labels
            ax.set_box_aspect([1, 1, 1])
            ax.set_xlabel('X')
            ax.set_ylabel('Z (Depth)')
            ax.set_zlabel('Y')
            ax.set_title('3D Point Cloud')
            
            # Use light gray background for better visibility
            ax.set_facecolor([0.9, 0.9, 0.9])
            fig.patch.set_facecolor([0.9, 0.9, 0.9])
            
            # Set an improved viewpoint
            ax.view_init(elev=20, azim=-35)  # Adjusted for better orientation
            
            # Remove grid for cleaner visualization
            ax.grid(False)
            
            # Normalize axis directions
            ax.set_xlim([-1, 1])
            ax.set_zlim([-1, 1])
            
            # Capture the plot as an image
            fig.tight_layout(pad=0)
            with io.BytesIO() as buf:
                fig.savefig(buf, format='png', bbox_inches='tight', facecolor=fig.get_facecolor())
                buf.seek(0)
                img = np.array(Image.open(buf))
            
            # Close the figure to free memory
            plt.close(fig)
            
            # Convert to float32 and normalize
            return img.astype(np.float32) / 255.0
            
        except Exception as e:
            logger.warning(f"Error rendering with Matplotlib: {str(e)}")
            # Fall back to a simple depth map visualization
            return self.render_depth_map(depth_map, width=width, height=height)
    
    def render_pointcloud_plotly(self, depth_map: np.ndarray, image: Image.Image,
                               width: int = 800, height: int = 600,
                               downsample_factor: int = 4) -> np.ndarray:
        """
        Render a 3D point cloud using Plotly for high-quality visualization.
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Rendered point cloud as numpy array
        """
        logger.info(f"Rendering point cloud with Plotly (downsample={downsample_factor})")
        
        try:
            # Normalize depth map
            if depth_map.max() <= 255:
                depth_norm = depth_map.astype(np.float32) / 255.0
            else:
                depth_norm = depth_map.astype(np.float32) / 1000.0

            # Get color image as RGB numpy array
            color_img = np.array(image.convert('RGB'))
            
            # Ensure dimensions match
            if color_img.shape[:2] != depth_map.shape[:2]:
                color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
            
            # Downsample for better performance
            h, w = depth_norm.shape
            y_indices, x_indices = np.mgrid[0:h:downsample_factor, 0:w:downsample_factor]
            
            # Get 3D coordinates
            z = depth_norm[y_indices, x_indices]
            x = x_indices
            y = y_indices
            colors = color_img[y_indices, x_indices]
            
            # Flatten arrays for scatter plot
            x = x.flatten()
            y = y.flatten()
            z = z.flatten()
            
            # Filter out invalid points
            valid = (z > 0)
            x = x[valid]
            y = y[valid]
            z = z[valid]
            
            # Normalize spatial coordinates
            x = (x - w/2) / w
            y = -(y - h/2) / h  # Invert Y axis for correct orientation
            
            # Extract RGB values from the image for Plotly
            r = colors[..., 0].flatten()[valid]
            g = colors[..., 1].flatten()[valid]
            b = colors[..., 2].flatten()[valid]
            
            # Create color strings in 'rgb(r,g,b)' format
            color_strs = [f'rgb({r[i]},{g[i]},{b[i]})' for i in range(len(r))]
            
            # Create the 3D scatter plot
            fig = go.Figure(data=[go.Scatter3d(
                x=x,
                y=z,  # Use z for y-axis (depth)
                z=-y,  # Negative y for correct orientation
                mode='markers',
                marker=dict(
                    size=2,
                    color=color_strs,
                    opacity=0.8
                )
            )])
            
            # Set layout for better visualization
            fig.update_layout(
                width=width,
                height=height,
                scene=dict(
                    xaxis_title='X',
                    yaxis_title='Z (Depth)',
                    zaxis_title='Y',
                    aspectratio=dict(x=1, y=1, z=1),
                    camera=dict(
                        eye=dict(x=1.2, y=1.2, z=1.2),
                        up=dict(x=0, y=0, z=1)
                    ),
                    xaxis=dict(showgrid=False, zeroline=False),
                    yaxis=dict(showgrid=False, zeroline=False),
                    zaxis=dict(showgrid=False, zeroline=False)
                ),
                margin=dict(l=0, r=0, b=0, t=0),
                paper_bgcolor='rgb(240, 240, 240)',
                plot_bgcolor='rgb(240, 240, 240)'
            )
            
            # Render to image
            img_bytes = fig.to_image(format="png")
            img = np.array(Image.open(io.BytesIO(img_bytes)))
            
            # Convert to float32 and normalize
            return img.astype(np.float32) / 255.0
            
        except Exception as e:
            logger.warning(f"Error rendering with Plotly: {str(e)}")
            # Fall back to Matplotlib rendering
            return self.render_pointcloud_matplotlib(depth_map, image, width, height, downsample_factor)
    
    def is_headless_environment(self) -> bool:
        """
        Check if we're running in a headless environment without X server
        
        Returns:
            True if headless, False otherwise
        """
        # Check for DISPLAY environment variable
        display = os.environ.get('DISPLAY', '')
        if not display:
            return True
            
        # Also check for common headless flags
        if 'SSH_CONNECTION' in os.environ and not os.environ.get('XAUTHORITY'):
            return True
            
        return False
    
    def render_pointcloud_pyvista(self, depth_map: np.ndarray, image: Image.Image,
                                width: int = 800, height: int = 600,
                                downsample_factor: int = 3) -> np.ndarray:
        """
        Render a 3D point cloud using PyVista (VTK-based) for high-quality rendering.
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Rendered point cloud as numpy array
        """
        logger.info(f"Rendering point cloud with PyVista (downsample={downsample_factor})")
        
        # Check if we're in a headless environment
        if self.is_headless_environment():
            logger.warning("Headless environment detected, PyVista requires X server. Falling back to Plotly.")
            return self.render_pointcloud_plotly(depth_map, image, width, height, downsample_factor)
        
        try:
            # Try to initialize xvfb if PyVista suggests it
            try:
                pv.start_xvfb()
                logger.info("Started virtual framebuffer (xvfb) for PyVista rendering")
            except Exception as e:
                logger.warning(f"Could not start virtual framebuffer: {str(e)}")
                
            # Create a PyVista plotter with the proper size
            plotter = pv.Plotter(off_screen=True, window_size=(width, height))
            
            # Normalize depth map
            if depth_map.max() <= 255:
                depth_norm = depth_map.astype(np.float32) / 255.0
            else:
                depth_norm = depth_map.astype(np.float32) / 1000.0

            # Get color image as RGB numpy array
            color_img = np.array(image.convert('RGB'))
            
            # Ensure dimensions match
            if color_img.shape[:2] != depth_map.shape[:2]:
                color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
            
            # Downsample for better performance
            h, w = depth_norm.shape
            y_indices, x_indices = np.mgrid[0:h:downsample_factor, 0:w:downsample_factor]
            
            # Get 3D coordinates
            z = depth_norm[y_indices, x_indices]
            x = x_indices
            y = y_indices
            colors = color_img[y_indices, x_indices] / 255.0
            
            # Flatten arrays
            x = x.flatten()
            y = y.flatten()
            z = z.flatten()
            rgb = colors.reshape(-1, 3)
            
            # Filter out invalid points
            valid = (z > 0)
            x = x[valid]
            y = y[valid]
            z = z[valid]
            rgb = rgb[valid]
            
            # Normalize spatial coordinates
            x = (x - w/2) / w
            y = -(y - h/2) / h  # Invert Y axis
            
            # Create point cloud data array
            points = np.column_stack((x, z, -y))  # Use -y for correct orientation
            
            # Create PyVista point cloud
            point_cloud = pv.PolyData(points)
            
            # Add RGB colors to the point cloud
            point_cloud['rgb'] = rgb
            
            # Add to the plotter with a good point size
            plotter.add_points(point_cloud, render_points_as_spheres=True, point_size=4, rgb=True)
            
            # Set up a nice camera view
            plotter.view_isometric()
            plotter.set_background([0.9, 0.9, 0.9])  # Light gray background
            
            # Add better lighting
            plotter.add_light(pv.Light(position=(1, 1, 1)))
            plotter.add_light(pv.Light(position=(-1, -1, -1), color='blue'))
            
            # Render to image
            plotter.show(auto_close=False)
            img = plotter.screenshot(return_img=True)
            plotter.close()
            
            # Convert to float32 and normalize
            return img.astype(np.float32) / 255.0
            
        except Exception as e:
            logger.warning(f"Error rendering with PyVista: {str(e)}")
            # Try Plotly next
            try:
                return self.render_pointcloud_plotly(depth_map, image, width, height, downsample_factor)
            except Exception as e2:
                logger.warning(f"Error with Plotly fallback: {str(e2)}")
                # Fall back to Matplotlib rendering
                return self.render_pointcloud_matplotlib(depth_map, image, width, height, downsample_factor)
    
    def depth_to_pointcloud(self, 
                           depth_map: np.ndarray, 
                           image: Image.Image,
                           focal_length: float = 525.0, 
                           scale_factor: float = 1000.0,
                           downsample_factor: int = 2) -> o3d.geometry.PointCloud:
        """
        Convert a depth map to a 3D point cloud
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image corresponding to the depth map
            focal_length: Camera focal length (approximation)
            scale_factor: Depth scale factor
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Open3D PointCloud object
        """
        logger.info(f"Converting depth map to point cloud (downsample={downsample_factor})")
        
        # Ensure depth_map is properly scaled from 0-255 to actual depth values
        if depth_map.max() <= 255:
            depth_norm = depth_map.astype(np.float32) / 255.0
        else:
            depth_norm = depth_map.astype(np.float32) / scale_factor
            
        # Get color image as RGB numpy array
        color_img = np.array(image.convert('RGB'))
        
        # Ensure dimensions match
        if color_img.shape[:2] != depth_map.shape[:2]:
            color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
        
        # Downsample for better performance
        if downsample_factor > 1:
            depth_norm = depth_norm[::downsample_factor, ::downsample_factor]
            color_img = color_img[::downsample_factor, ::downsample_factor]
            
        # Get image dimensions
        height, width = depth_norm.shape
        
        # Create meshgrid of coordinates
        y, x = np.mgrid[0:height, 0:width]
        
        # Compute 3D coordinates
        # Center the coordinate system at the image center
        cx, cy = width / 2, height / 2
        x = (x - cx) * depth_norm / focal_length
        y = (y - cy) * depth_norm / focal_length
        z = depth_norm
        
        # Flatten and combine into points
        points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)
        colors = color_img.reshape(-1, 3) / 255.0
        
        # Remove invalid points (zero depth)
        valid_indices = z.flatten() > 0
        points = points[valid_indices]
        colors = colors[valid_indices]
        
        # Create Open3D point cloud
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # Optionally filter noise and outliers
        pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
        
        return pcd
    
    def pointcloud_to_mesh(self, pcd: o3d.geometry.PointCloud, depth_threshold: float = 0.05) -> o3d.geometry.TriangleMesh:
        """
        Convert point cloud to mesh
        
        Args:
            pcd: Open3D PointCloud
            depth_threshold: Threshold for depth difference between connected points
            
        Returns:
            Open3D TriangleMesh
        """
        logger.info("Converting point cloud to mesh")
        
        # Estimate normals if they don't exist
        if not pcd.has_normals():
            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
            pcd.orient_normals_towards_camera_location()
        
        # Create mesh using Poisson surface reconstruction
        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)
        
        # Remove low density vertices
        vertices_to_remove = densities < np.quantile(densities, 0.1)
        mesh.remove_vertices_by_mask(vertices_to_remove)
        
        return mesh
    
    def save_pointcloud(self, pcd: o3d.geometry.PointCloud, filename: str) -> str:
        """
        Save point cloud to file
        
        Args:
            pcd: Open3D PointCloud
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as PLY
        output_path = f"{filename}.ply"
        o3d.io.write_point_cloud(output_path, pcd)
        logger.info(f"Point cloud saved to {output_path}")
        return output_path
    
    def save_mesh(self, mesh: o3d.geometry.TriangleMesh, filename: str) -> str:
        """
        Save mesh to file
        
        Args:
            mesh: Open3D TriangleMesh
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as OBJ
        output_path = f"{filename}.obj"
        o3d.io.write_triangle_mesh(output_path, mesh)
        logger.info(f"Mesh saved to {output_path}")
        return output_path
    
    def visualize_pointcloud(self, pcd: o3d.geometry.PointCloud) -> None:
        """
        Visualize point cloud using Open3D visualizer
        
        Args:
            pcd: Open3D PointCloud
        """
        o3d.visualization.draw_geometries([pcd])
    
    def visualize_mesh(self, mesh: o3d.geometry.TriangleMesh) -> None:
        """
        Visualize mesh using Open3D visualizer
        
        Args:
            mesh: Open3D TriangleMesh
        """
        o3d.visualization.draw_geometries([mesh])
    
    def render_pointcloud_image(self, pcd: o3d.geometry.PointCloud, 
                               width: int = 800, height: int = 600,
                               zoom: float = 0.8) -> np.ndarray:
        """
        Render point cloud to image without opening a window
        
        Args:
            pcd: Open3D PointCloud
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering point cloud with {len(pcd.points)} points")
        
        # Check if point cloud has points
        if len(pcd.points) == 0:
            logger.warning("Point cloud is empty, creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(pcd)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire point cloud
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the point cloud
                bbox = pcd.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().point_size = 3.0  # Larger points
            
            # Debugging camera info
            logger.info(f"Camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered image appears to be all black, creating a fallback")
                # Create a fallback with a message
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering point cloud: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
    
    def render_mesh_image(self, mesh: o3d.geometry.TriangleMesh, 
                         width: int = 800, height: int = 600,
                         zoom: float = 0.8) -> np.ndarray:
        """
        Render mesh to image without opening a window
        
        Args:
            mesh: Open3D TriangleMesh
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering mesh with {len(mesh.triangles)} triangles")
        
        # Check if mesh is valid
        if len(mesh.triangles) == 0:
            logger.warning("Mesh is empty (no triangles), creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(mesh)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire mesh
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the mesh
                bbox = mesh.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().mesh_show_back_face = True
            vis.get_render_option().light_on = True
            
            # Debugging camera info
            logger.info(f"Mesh camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered mesh image appears to be all black, creating a fallback")
                
                # Add a white grid pattern to gray background to show something
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                
                # Create mesh texture visualization
                for i in range(0, height, 20):
                    for j in range(0, width, 20):
                        # Create a grid pattern
                        if (i + j) % 40 == 0:
                            fallback_img[i:i+10, j:j+10] = [0.9, 0.9, 0.9]  # Make squares lighter
                
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering mesh: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img

    def enhanced_reconstruction(self, depth_map: np.ndarray, image: Image.Image,
                              width: int = 800, height: int = 600,
                              downsample_factor: int = 2) -> Tuple[np.ndarray, o3d.geometry.PointCloud]:
        """
        Create an enhanced 3D reconstruction using depth gradient analysis, confidence-based 
        filtering, and advanced rendering approaches.
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            width: Desired output width
            height: Desired output height
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Tuple of (rendered image, point cloud)
        """
        logger.info("Creating enhanced 3D reconstruction...")
        
        try:
            # Debug information about the input depth map
            logger.info(f"Depth map shape: {depth_map.shape}, range: [{depth_map.min()}, {depth_map.max()}]")
            
            # Ensure the depth map is valid
            if depth_map.max() <= 0:
                logger.warning("Invalid depth map (all zeros or negative)")
                # Return a fallback colored depth map
                return self.render_depth_map(depth_map, width=width, height=height), o3d.geometry.PointCloud()
            
            # Convert to float for gradient calculation
            depth_float = depth_map.astype(np.float32)
            
            # Calculate depth confidence using gradient analysis
            # Areas with high gradient (edges) are less reliable
            depth_gradx = cv2.Sobel(depth_float, cv2.CV_32F, 1, 0, ksize=3)
            depth_grady = cv2.Sobel(depth_float, cv2.CV_32F, 0, 1, ksize=3)
            depth_grad_mag = np.sqrt(depth_gradx**2 + depth_grady**2)
            
            # Debug gradient info
            logger.info(f"Gradient magnitude range: [{depth_grad_mag.min()}, {depth_grad_mag.max()}]")
            
            # Normalize gradient magnitude
            if depth_grad_mag.max() > 0:
                confidence = 1.0 - (depth_grad_mag / depth_grad_mag.max())
            else:
                confidence = np.ones_like(depth_map)
            
            # Lower the confidence threshold to keep more points while still filtering noise
            confidence_threshold = 0.5  # More forgiving threshold
            confidence_mask = confidence > confidence_threshold
            
            # Count points before and after confidence filtering
            total_points = depth_map.size
            confident_points = np.sum(confidence_mask)
            logger.info(f"Confidence filtering: kept {confident_points}/{total_points} points ({confident_points/total_points*100:.1f}%)")
            
            # Apply confidence mask to depth map
            filtered_depth = depth_map.copy()
            filtered_depth[~confidence_mask] = 0
            
            # Verify filtered depth map has non-zero values
            if np.count_nonzero(filtered_depth) == 0:
                logger.warning("Filtered depth map is empty, using original depth map")
                filtered_depth = depth_map  # Fallback to original
            
            # Create an enhanced colored depth map visualization as a reliable fallback
            enhanced_depth_viz = self.render_depth_map(filtered_depth, width=width, height=height)
            
            # Create a higher quality point cloud with confidence filtering
            pcd = self.depth_to_pointcloud(
                depth_map=filtered_depth,
                image=image,
                downsample_factor=downsample_factor
            )
            
            # Check if point cloud generation succeeded
            if pcd is None or len(pcd.points) == 0:
                logger.warning("Failed to generate point cloud, falling back to colored depth map")
                return enhanced_depth_viz, o3d.geometry.PointCloud()
                
            logger.info(f"Generated point cloud with {len(pcd.points)} points")
            
            # Use a cascading set of rendering approaches, from most advanced to most reliable
            render_img = None
            render_methods = [
                ("PyVista", lambda: self.render_pointcloud_pyvista(filtered_depth, image, width, height, downsample_factor)),
                ("Plotly", lambda: self.render_pointcloud_plotly(filtered_depth, image, width, height, downsample_factor)), 
                ("Matplotlib", lambda: self.render_pointcloud_matplotlib(filtered_depth, image, width, height, downsample_factor))
            ]
            
            # Try each rendering method in order until one succeeds
            for method_name, render_func in render_methods:
                try:
                    logger.info(f"Attempting 3D rendering with {method_name}")
                    render_img = render_func()
                    
                    # Validate the rendered image
                    mean_value = render_img.mean()
                    logger.info(f"{method_name} rendering result: mean value = {mean_value}")
                    
                    # Check if the image is too bright or too dark
                    if mean_value < 0.1 or mean_value > 0.95:
                        logger.warning(f"{method_name} rendering produced invalid image (too bright/dark)")
                        continue
                    
                    logger.info(f"Successfully rendered with {method_name}")
                    break  # Stop if we got a good render
                    
                except Exception as e:
                    logger.warning(f"{method_name} rendering failed: {str(e)}")
            
            # If all rendering methods failed, use the color depth map
            if render_img is None or render_img.mean() < 0.1 or render_img.mean() > 0.95:
                logger.warning("All 3D rendering methods failed, using colored depth map")
                return enhanced_depth_viz, pcd
                
            return render_img, pcd
            
        except Exception as e:
            logger.error(f"Enhanced reconstruction failed: {str(e)}")
            # Return default depth map and empty point cloud as fallback
            render_img = self.render_depth_map(depth_map, width=width, height=height)
            pcd = o3d.geometry.PointCloud()  # Empty point cloud
            return render_img, pcd
            
    def create_error_image(self, width: int = 800, height: int = 600, message: str = "Error processing image") -> np.ndarray:
        """
        Create an error image with text for when visualization fails completely
        
        Args:
            width: Image width
            height: Image height
            message: Error message to display
            
        Returns:
            Error image as numpy array
        """
        # Create a gray background
        img = np.ones((height, width, 3), dtype=np.float32) * 0.8
        
        # Use OpenCV to add text
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        font_thickness = 2
        text_color = (0.2, 0.2, 0.2)  # Dark gray color for text
        
        # Split message by newlines and render each line
        lines = message.split('\n')
        line_height = 30
        y_position = height // 2 - (len(lines) * line_height) // 2
        
        for line in lines:
            # Get the size of the text
            text_size = cv2.getTextSize(line, font, font_scale, font_thickness)[0]
            x_position = (width - text_size[0]) // 2  # Center text horizontally
            
            # Put the text on the image
            cv2.putText(
                img, line, (x_position, y_position), 
                font, font_scale, text_color, font_thickness
            )
            y_position += line_height
            
        return img
    
    def visualize_3d(self, depth_map: np.ndarray, image: Image.Image, 
                    method: str = "depth_map", width: int = 800, height: int = 600) -> np.ndarray:
        """
        Unified method to visualize depth data using various methods with automatic fallbacks
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image
            method: Visualization method to use (from self.visualization_methods)
            width: Desired output width
            height: Desired output height
            
        Returns:
            Visualization as numpy array (RGB float image)
        """
        logger.info(f"Visualizing 3D with method: {method}")
        
        # First check if the method is valid
        if method not in self.visualization_methods:
            logger.warning(f"Invalid visualization method: {method}, falling back to depth_map")
            method = "depth_map"
            
        # Check if inputs are valid
        if depth_map is None or depth_map.size == 0:
            logger.warning("Invalid depth map provided")
            return self.create_error_image(
                width, height, 
                "Unable to create 3D visualization.\nNo valid depth map available.\nTry a different image."
            )
        
        # Check if image is valid
        if image is None:
            logger.warning("Invalid image provided")
            # Try to use depth map alone if possible
            if method == "depth_map":
                return self.render_depth_map(depth_map, width=width, height=height)
            else:
                # For other methods that need the color image, create a grayscale image from depth
                try:
                    # Create a colored version of depth map to use as texture
                    normalized = cv2.normalize(depth_map, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                    colored = cv2.applyColorMap(normalized, cv2.COLORMAP_INFERNO)
                    colored_rgb = cv2.cvtColor(colored, cv2.COLOR_BGR2RGB)
                    # Convert to PIL image
                    image = Image.fromarray(colored_rgb)
                except Exception as e:
                    logger.warning(f"Failed to create substitute color image: {str(e)}")
                    return self.render_depth_map(depth_map, width=width, height=height)
        
        # Handle errors from previous processing steps (as seen in feedback)
        if hasattr(image, 'size'):
            # Make sure image has the right mode
            if image.mode != 'RGB':
                image = image.convert('RGB')
        else:
            logger.warning("Image object is not a valid PIL image")
            return self.render_depth_map(depth_map, width=width, height=height)
        
        # Process based on method with fallbacks
        try:
            if method == "depth_map":
                # Direct depth map visualization (most reliable)
                return self.render_depth_map(depth_map, width=width, height=height)
                
            elif method == "pointcloud_mpl":
                # Matplotlib point cloud visualization (good fallback)
                return self.render_pointcloud_matplotlib(depth_map, image, 
                                                      width=width, height=height)
                
            elif method == "enhanced_3d":
                # Try to use the enhanced 3D reconstruction 
                try:
                    render_img, _ = self.enhanced_reconstruction(
                        depth_map=depth_map,
                        image=image,
                        width=width,
                        height=height
                    )
                    return render_img
                except RuntimeError as cuda_err:
                    # Handle CUDA-specific errors by falling back to CPU methods
                    if "CUDA" in str(cuda_err):
                        logger.warning(f"CUDA error in enhanced reconstruction: {str(cuda_err)}")
                        logger.info("Falling back to matplotlib visualization (CPU-based)")
                        return self.render_pointcloud_matplotlib(depth_map, image, width=width, height=height)
                    else:
                        # Re-raise non-CUDA runtime errors
                        raise
                
            else:
                # Unknown method, fall back to depth map
                logger.warning(f"Unknown visualization method: {method}, falling back to depth_map")
                return self.render_depth_map(depth_map, width=width, height=height)
                
        except Exception as e:
            # If all else fails, fall back to direct depth map visualization
            logger.warning(f"3D visualization failed with error: {str(e)}, falling back to depth map")
            
            # Try depth map rendering which should never fail
            try:
                return self.render_depth_map(depth_map, width=width, height=height)
            except Exception as render_error:
                # If even depth map rendering fails, return error image
                logger.error(f"Depth map rendering also failed: {str(render_error)}")
                return self.create_error_image(
                    width, height, 
                    f"3D visualization failed.\nError: {type(e).__name__}"
                )

import os
import numpy as np
import open3d as o3d
import matplotlib.pyplot as plt
from PIL import Image
import cv2
import logging
from typing import List, Dict, Tuple, Optional, Union, Any

logger = logging.getLogger(__name__)

class DepthReconstructor:
    """
    Class for 3D reconstruction from depth maps generated by the ImageProcessor
    """
    
    def __init__(self):
        """Initialize the 3D reconstruction module"""
        logger.info("Initializing 3D Reconstructor")
    
    def depth_to_pointcloud(self, 
                           depth_map: np.ndarray, 
                           image: Image.Image,
                           focal_length: float = 525.0, 
                           scale_factor: float = 1000.0,
                           downsample_factor: int = 2) -> o3d.geometry.PointCloud:
        """
        Convert a depth map to a 3D point cloud
        
        Args:
            depth_map: Depth map as numpy array
            image: Original color image corresponding to the depth map
            focal_length: Camera focal length (approximation)
            scale_factor: Depth scale factor
            downsample_factor: Factor by which to downsample the point cloud
            
        Returns:
            Open3D PointCloud object
        """
        logger.info(f"Converting depth map to point cloud (downsample={downsample_factor})")
        
        # Ensure depth_map is properly scaled from 0-255 to actual depth values
        if depth_map.max() <= 255:
            depth_norm = depth_map.astype(np.float32) / 255.0
        else:
            depth_norm = depth_map.astype(np.float32) / scale_factor
            
        # Get color image as RGB numpy array
        color_img = np.array(image.convert('RGB'))
        
        # Ensure dimensions match
        if color_img.shape[:2] != depth_map.shape[:2]:
            color_img = cv2.resize(color_img, (depth_map.shape[1], depth_map.shape[0]))
        
        # Downsample for better performance
        if downsample_factor > 1:
            depth_norm = depth_norm[::downsample_factor, ::downsample_factor]
            color_img = color_img[::downsample_factor, ::downsample_factor]
            
        # Get image dimensions
        height, width = depth_norm.shape
        
        # Create meshgrid of coordinates
        y, x = np.mgrid[0:height, 0:width]
        
        # Compute 3D coordinates
        # Center the coordinate system at the image center
        cx, cy = width / 2, height / 2
        x = (x - cx) * depth_norm / focal_length
        y = (y - cy) * depth_norm / focal_length
        z = depth_norm
        
        # Flatten and combine into points
        points = np.stack((x.flatten(), y.flatten(), z.flatten()), axis=1)
        colors = color_img.reshape(-1, 3) / 255.0
        
        # Remove invalid points (zero depth)
        valid_indices = z.flatten() > 0
        points = points[valid_indices]
        colors = colors[valid_indices]
        
        # Create Open3D point cloud
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # Optionally filter noise and outliers
        pcd, _ = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
        
        return pcd
    
    def pointcloud_to_mesh(self, pcd: o3d.geometry.PointCloud, depth_threshold: float = 0.05) -> o3d.geometry.TriangleMesh:
        """
        Convert point cloud to mesh
        
        Args:
            pcd: Open3D PointCloud
            depth_threshold: Threshold for depth difference between connected points
            
        Returns:
            Open3D TriangleMesh
        """
        logger.info("Converting point cloud to mesh")
        
        # Estimate normals if they don't exist
        if not pcd.has_normals():
            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))
            pcd.orient_normals_towards_camera_location()
        
        # Create mesh using Poisson surface reconstruction
        mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(pcd, depth=8)
        
        # Remove low density vertices
        vertices_to_remove = densities < np.quantile(densities, 0.1)
        mesh.remove_vertices_by_mask(vertices_to_remove)
        
        return mesh
    
    def save_pointcloud(self, pcd: o3d.geometry.PointCloud, filename: str) -> str:
        """
        Save point cloud to file
        
        Args:
            pcd: Open3D PointCloud
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as PLY
        output_path = f"{filename}.ply"
        o3d.io.write_point_cloud(output_path, pcd)
        logger.info(f"Point cloud saved to {output_path}")
        return output_path
    
    def save_mesh(self, mesh: o3d.geometry.TriangleMesh, filename: str) -> str:
        """
        Save mesh to file
        
        Args:
            mesh: Open3D TriangleMesh
            filename: Name for the output file (without extension)
            
        Returns:
            Path to the saved file
        """
        # Save as OBJ
        output_path = f"{filename}.obj"
        o3d.io.write_triangle_mesh(output_path, mesh)
        logger.info(f"Mesh saved to {output_path}")
        return output_path
    
    def visualize_pointcloud(self, pcd: o3d.geometry.PointCloud) -> None:
        """
        Visualize point cloud using Open3D visualizer
        
        Args:
            pcd: Open3D PointCloud
        """
        o3d.visualization.draw_geometries([pcd])
    
    def visualize_mesh(self, mesh: o3d.geometry.TriangleMesh) -> None:
        """
        Visualize mesh using Open3D visualizer
        
        Args:
            mesh: Open3D TriangleMesh
        """
        o3d.visualization.draw_geometries([mesh])
    
    def render_pointcloud_image(self, pcd: o3d.geometry.PointCloud, 
                               width: int = 800, height: int = 600,
                               zoom: float = 0.8) -> np.ndarray:
        """
        Render point cloud to image without opening a window
        
        Args:
            pcd: Open3D PointCloud
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering point cloud with {len(pcd.points)} points")
        
        # Check if point cloud has points
        if len(pcd.points) == 0:
            logger.warning("Point cloud is empty, creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(pcd)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire point cloud
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the point cloud
                bbox = pcd.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().point_size = 3.0  # Larger points
            
            # Debugging camera info
            logger.info(f"Camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered image appears to be all black, creating a fallback")
                # Create a fallback with a message
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering point cloud: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
    
    def render_mesh_image(self, mesh: o3d.geometry.TriangleMesh, 
                         width: int = 800, height: int = 600,
                         zoom: float = 0.8) -> np.ndarray:
        """
        Render mesh to image without opening a window
        
        Args:
            mesh: Open3D TriangleMesh
            width: Image width
            height: Image height
            zoom: Camera zoom factor
            
        Returns:
            Rendered image as numpy array
        """
        # Debug information
        logger.info(f"Rendering mesh with {len(mesh.triangles)} triangles")
        
        # Check if mesh is valid
        if len(mesh.triangles) == 0:
            logger.warning("Mesh is empty (no triangles), creating a message image instead")
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
            
        vis = o3d.visualization.Visualizer()
        vis.create_window(visible=False, width=width, height=height)
        vis.add_geometry(mesh)
        
        # Configure camera view
        try:
            view_control = vis.get_view_control()
            if view_control is not None:
                # Position the camera to see the entire mesh
                camera_params = view_control.convert_to_pinhole_camera_parameters()
                
                # Get the bounding box of the mesh
                bbox = mesh.get_axis_aligned_bounding_box()
                center = bbox.get_center()
                
                # Set a reasonable default viewpoint
                view_control.set_front([0, 0, -1])  # Look at the model from the front
                view_control.set_up([0, -1, 0])     # Up direction
                view_control.set_lookat(center)     # Look at the center of the model
                view_control.set_zoom(zoom)
            
            # Use a light gray background for better visibility
            vis.get_render_option().background_color = np.asarray([0.8, 0.8, 0.8])  # Light gray
            vis.get_render_option().mesh_show_back_face = True
            vis.get_render_option().light_on = True
            
            # Debugging camera info
            logger.info(f"Mesh camera configured: zoom={zoom}, looking at center={bbox.get_center()}")
            
            # Render
            vis.poll_events()
            vis.update_renderer()
            image = vis.capture_screen_float_buffer(do_render=True)
            vis.destroy_window()
            
            # Check if the image is all black (or very dark)
            img_array = np.asarray(image)
            if img_array.mean() < 0.1:  # If mean pixel value is very low (almost black)
                logger.warning("Rendered mesh image appears to be all black, creating a fallback")
                
                # Add a white grid pattern to gray background to show something
                fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
                
                # Create mesh texture visualization
                for i in range(0, height, 20):
                    for j in range(0, width, 20):
                        # Create a grid pattern
                        if (i + j) % 40 == 0:
                            fallback_img[i:i+10, j:j+10] = [0.9, 0.9, 0.9]  # Make squares lighter
                
                return fallback_img
                
            return img_array
        except Exception as e:
            logger.warning(f"Error rendering mesh: {str(e)}")
            # Create a fallback image with a light background
            fallback_img = np.ones((height, width, 3), dtype=np.float32) * 0.8  # Light gray
            return fallback_img
